# modules/vision.py
"""
Computer Vision –º–æ–¥—É–ª—å –¥–ª—è Bauflex AI Brain.
–î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ (YOLO), –æ—Ü–µ–Ω–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤, –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö.

–ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø v2.2 (–ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º code review):
- BUGFIX: –£—Å—Ç—Ä–∞–Ω–µ–Ω–æ –¥–≤–æ–π–Ω–æ–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (Eyes.analyze_scene —Ç–µ–ø–µ—Ä—å
  –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–π frame; VisionSystem.process_scene –¥–µ–∫–æ–¥–∏—Ä—É–µ—Ç –û–î–ò–ù —Ä–∞–∑)
- –ñ—ë—Å—Ç–∫–∏–π –º–∞–ø–ø–∏–Ω–≥ –∫–ª–∞—Å—Å–æ–≤ YOLO (BAUFLEX_CLASS_MAP): beam / pipe_obstacle /
  safety_equipment –∏ —Ç.–¥. ‚Äî —Ñ–∏–∑–∏—á–µ—Å–∫–∏–π –¥–≤–∏–∂–æ–∫ —Ä–∞–∑–ª–∏—á–∞–µ—Ç –Ω–µ—Å—É—â–∏–µ –∏ –Ω–µ–Ω–µ—Å—É—â–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã
- _check_occlusion: –¥–æ–±–∞–≤–ª–µ–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ ¬´–æ–±—ä–µ–∫—Ç –∑–∞–Ω–∏–º–∞–µ—Ç >80% –∫–∞–¥—Ä–∞¬ª (–Ω–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
- –ù–æ–≤—ã–π –º–µ—Ç–æ–¥ _check_depth_occlusion: IoU-–∞–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–π –º–µ–∂–¥—É –æ–±—ä–µ–∫—Ç–∞–º–∏
- –ù–æ–≤—ã–π –º–µ—Ç–æ–¥ _check_ar_drift: —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä—ã –∏–∑ YOLO —Å —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ–º –º–µ–∂–¥—É AR-—Ç–æ—á–∫–∞–º–∏,
  —Å–∏–≥–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ –¥—Ä–∏—Ñ—Ç–µ ARCore –∏–ª–∏ –æ—à–∏–±–∫–µ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞

–ü—Ä–µ–¥—ã–¥—É—â–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è v2.1:
- RGB ‚Üí BGR –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –¥–ª—è YOLO
- –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ focal_length (fx, fy)
- –î–µ—Ç–µ–∫—Ü–∏—è occlusion (–æ–±—Ä–µ–∑–∫–∏ –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ –∫—Ä–∞—è–º –∫–∞–¥—Ä–∞)
- Resize –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è blur-–∞–Ω–∞–ª–∏–∑–∞
- –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
"""
from __future__ import annotations

import io
import logging
import base64
from typing import Any, Dict, List, Optional, Tuple

import numpy as np

# === –ò–ú–ü–û–†–¢–´ –° –û–ë–†–ê–ë–û–¢–ö–û–ô –û–®–ò–ë–û–ö ===
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    cv2 = None
    CV2_AVAILABLE = False

try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    Image = None
    PIL_AVAILABLE = False

try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    YOLO = None
    YOLO_AVAILABLE = False


# === –ù–ê–°–¢–†–û–ô–ö–ê –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø ===
logger = logging.getLogger(__name__)


class Eyes:
    """
    –î–µ—Ç–µ–∫—Ç–æ—Ä –æ–±—ä–µ–∫—Ç–æ–≤ + –æ—Ü–µ–Ω–∫–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤.
    
    –£–ª—É—á—à–µ–Ω–∏—è v2.1:
    - –ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å BGR (–¥–ª—è YOLO)
    - –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ focal_length (fx, fy –∏–∑ ARCore)
    - Fallback —Ä–µ–∂–∏–º –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ YOLO
    """

    # –ñ—ë—Å—Ç–∫–∏–π –º–∞–ø–ø–∏–Ω–≥ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è Bauflex.
    # –ö–†–ò–¢–ò–ß–ù–û: —Ä–∞–∑–ª–∏—á–∞—Ç—å –Ω–µ—Å—É—â–∏–µ –±–∞–ª–∫–∏ –∏ —Ç—Ä—É–±—ã –≤–µ–Ω—Ç–∏–ª—è—Ü–∏–∏,
    # –∏–Ω–∞—á–µ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–π –¥–≤–∏–∂–æ–∫ –±—É–¥–µ—Ç –ø—ã—Ç–∞—Ç—å—Å—è –∫—Ä–µ–ø–∏—Ç—å –ª–µ—Å–∞ –∫ –ø–ª–∞—Å—Ç–∏–∫—É!
    BAUFLEX_CLASS_MAP: Dict[int, str] = {
        0: "beam",              # –ù–µ—Å—É—â–∞—è –±–∞–ª–∫–∞ ‚Äî —Ç–æ—á–∫–∞ –∫—Ä–µ–ø–ª–µ–Ω–∏—è –ª–µ—Å–æ–≤
        1: "pipe_obstacle",     # –¢—Ä—É–±–∞-–ø—Ä–µ–ø—è—Ç—Å—Ç–≤–∏–µ ‚Äî –ù–ï–õ–¨–ó–Ø –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ –æ–ø–æ—Ä—É
        2: "safety_equipment",  # –ó–∞—â–∏—Ç–Ω–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ (–∫–∞—Å–∫–∞, –æ–≥—Ä–∞–∂–¥–µ–Ω–∏–µ)
        3: "column",            # –ö–æ–ª–æ–Ω–Ω–∞ / —Å—Ç–æ–π–∫–∞
        4: "floor_slab",        # –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ
        5: "cable_tray",        # –ö–∞–±–µ–ª—å–Ω—ã–π –ª–æ—Ç–æ–∫ ‚Äî –ø—Ä–µ–ø—è—Ç—Å—Ç–≤–∏–µ
    }

    def __init__(self, model_path: str = "yolov8n.pt") -> None:
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞.

        Args:
            model_path: –ø—É—Ç—å –∫ –≤–µ—Å–∞–º YOLO –º–æ–¥–µ–ª–∏
        """
        self._ensure_dependencies()
        
        self.model = None
        if YOLO_AVAILABLE:
            try:
                self.model = YOLO(model_path)
                logger.info(f"‚úì YOLO model loaded: {model_path}")
            except Exception as e:
                logger.error(f"‚úó Failed to load YOLO model: {e}")
                self.model = None
        else:
            logger.warning("‚ö†Ô∏è YOLO not available. Running in fallback mode.")

    def _ensure_dependencies(self) -> None:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π."""
        issues = []
        
        if not CV2_AVAILABLE:
            issues.append("opencv-python (cv2) is required but not installed")
        
        if not PIL_AVAILABLE:
            issues.append("Pillow (PIL) is required but not installed")
        
        if not YOLO_AVAILABLE:
            logger.warning("ultralytics (YOLO) not installed - will use fallback detection")
        
        if issues:
            error_msg = "Missing critical dependencies:\n" + "\n".join(f"  - {i}" for i in issues)
            logger.error(error_msg)
            raise ImportError(error_msg)

    def analyze_scene(
        self,
        image_bytes: Optional[bytes] = None,
        distance_to_target: float = 0.0,
        focal_length: Optional[float] = None,
        focal_length_x: Optional[float] = None,
        focal_length_y: Optional[float] = None,
        frame: Optional[np.ndarray] = None,
    ) -> List[Dict[str, Any]]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ü–µ–Ω—É: –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –æ–±—ä–µ–∫—Ç—ã –∏ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –∏—Ö —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã.

        –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø v2.2: –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –ª–∏–±–æ image_bytes, –ª–∏–±–æ —É–∂–µ –≥–æ—Ç–æ–≤—ã–π frame.
        –ï—Å–ª–∏ frame –ø–µ—Ä–µ–¥–∞–Ω ‚Äî –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è (—ç–∫–æ–Ω–æ–º–∏—è –Ω–∞ –º–æ–±–∏–ª—å–Ω–æ–º CPU).

        Args:
            image_bytes: –±–∞–π—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –µ—Å–ª–∏ frame –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω)
            distance_to_target: —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –æ–±—ä–µ–∫—Ç–∞ (–º–µ—Ç—Ä—ã), –æ—Ç ARCore
            focal_length: —Ñ–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (—É—Å—Ç–∞—Ä–µ–≤—à–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
            focal_length_x: —Ñ–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø–æ –æ—Å–∏ X (–ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ)
            focal_length_y: —Ñ–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø–æ –æ—Å–∏ Y (–ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ)
            frame: –≥–æ—Ç–æ–≤—ã–π BGR-–∫–∞–¥—Ä np.ndarray (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞–¥ image_bytes)

        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ —Å —Ä–∞–∑–º–µ—Ä–∞–º–∏ –∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏

        Raises:
            ValueError: –µ—Å–ª–∏ distance <= 0 –∏–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω –Ω–∏ image_bytes, –Ω–∏ frame
        """
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if distance_to_target <= 0:
            raise ValueError(f"distance_to_target must be > 0, got {distance_to_target}")

        # –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ: –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤—ã–π frame –∏–ª–∏ –¥–µ–∫–æ–¥–∏—Ä—É–µ–º –∏–∑ –±–∞–π—Ç
        if frame is None:
            if image_bytes is not None:
                frame = self._decode_image_bgr(image_bytes)
            else:
                raise ValueError("Either image_bytes or frame must be provided")
        # –ï—Å–ª–∏ frame —É–∂–µ –ø–µ—Ä–µ–¥–∞–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ

        # –§–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: fx/fy > focal_length > default)
        fx = focal_length_x or focal_length or 800.0
        fy = focal_length_y or focal_length or 800.0

        if focal_length_x is None and focal_length_y is None and focal_length is None:
            logger.warning(
                "‚ö†Ô∏è Using default focal_length=800px. "
                "For better accuracy, provide focal_length_x and focal_length_y from ARCore."
            )

        h, w = frame.shape[:2]

        detections: List[Dict[str, Any]] = []
        
        # YOLO –¥–µ—Ç–µ–∫—Ü–∏—è
        if self.model is not None:
            try:
                # YOLO –æ–∂–∏–¥–∞–µ—Ç BGR (–∏–ª–∏ RGB, –Ω–æ –º—ã –ø–µ—Ä–µ–¥–∞–µ–º BGR –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ —Å cv2)
                results = self.model.predict(source=frame, verbose=False)
                detections = self._yolo_to_objects(results, distance_to_target, fx, fy)
            except Exception as e:
                logger.error(f"YOLO prediction failed: {e}")
                detections = []

        # Fallback: –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
        if not detections:
            logger.warning("No objects detected. Using full frame as fallback.")
            detections = [
                {
                    "type": "unknown",
                    "confidence": 0.5,
                    "real_width_m": round((w * distance_to_target) / fx, 3),
                    "real_height_m": round((h * distance_to_target) / fy, 3),
                    "bbox": [0, 0, w, h],
                    "center": [w // 2, h // 2],
                }
            ]
        
        return detections

    def _decode_image_bgr(self, image_bytes: bytes | str) -> np.ndarray:
        """
        –î–µ–∫–æ–¥–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ BGR —Ñ–æ—Ä–º–∞—Ç (–¥–ª—è YOLO –∏ cv2).
        
        –ö–†–ò–¢–ò–ß–ù–û: PIL –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç RGB, YOLO —Ä–∞–±–æ—Ç–∞–µ—Ç —Å BGR.
        –ë–µ–∑ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Ç–æ—á–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø–∞–¥–∞–µ—Ç!
        
        Args:
            image_bytes: –±–∞–π—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        
        Returns:
            numpy array –≤ BGR —Ñ–æ—Ä–º–∞—Ç–µ (H, W, 3)
        """
        if isinstance(image_bytes, str):
            # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ base64-–ø–æ—Ç–æ–∫–∞ –æ—Ç Android (—Å –≤–æ–∑–º–æ–∂–Ω—ã–º data URI –ø—Ä–µ—Ñ–∏–∫—Å–æ–º)
            payload = image_bytes.split(",", 1)[-1] if image_bytes.startswith("data:") else image_bytes
            image_bytes = base64.b64decode(payload)

        if CV2_AVAILABLE:
            # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø—É—Ç—å: cv2 –Ω–∞–ø—Ä—è–º—É—é –¥–µ–∫–æ–¥–∏—Ä—É–µ—Ç –≤ BGR
            nparr = np.frombuffer(image_bytes, np.uint8)
            frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if frame is None:
                raise ValueError("Failed to decode image with cv2")
            
            return frame
        
        elif PIL_AVAILABLE:
            # Fallback —á–µ—Ä–µ–∑ PIL: RGB ‚Üí BGR
            img = Image.open(io.BytesIO(image_bytes)).convert("RGB")
            frame_rgb = np.array(img)
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º RGB ‚Üí BGR
            frame_bgr = frame_rgb[:, :, ::-1]
            
            return frame_bgr
        
        else:
            raise ImportError("Neither cv2 nor PIL is available for image decoding")

    def _yolo_to_objects(
        self, 
        results: Any, 
        distance: float, 
        fx: float, 
        fy: float
    ) -> List[Dict[str, Any]]:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã YOLO –≤ —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Ä–∞–∑–º–µ—Ä–∞–º–∏.
        
        Args:
            results: –≤—ã—Ö–æ–¥ YOLO model.predict()
            distance: —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –æ–±—ä–µ–∫—Ç–∞ (–º)
            fx, fy: —Ñ–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø–æ –æ—Å—è–º X –∏ Y (–ø–∏–∫—Å–µ–ª–∏)
        
        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤
        """
        objects: List[Dict[str, Any]] = []
        
        for result in results:
            names = getattr(result, "names", {})
            
            for box in result.boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
                conf = float(box.conf[0])
                cls = int(box.cls[0])
                
                # –†–∞–∑–º–µ—Ä—ã –≤ –ø–∏–∫—Å–µ–ª—è—Ö
                px_w = max(1, x2 - x1)
                px_h = max(1, y2 - y1)
                
                # –†–µ–∞–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã: (–ø–∏–∫—Å–µ–ª–∏ * —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ) / —Ñ–æ–∫—É—Å–Ω–æ–µ_—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
                real_w = (px_w * distance) / fx
                real_h = (px_h * distance) / fy
                
                # –ú–∞–ø–ø–∏–Ω–≥ –∫–ª–∞—Å—Å–æ–≤: —Å–Ω–∞—á–∞–ª–∞ Bauflex-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å,
                # –∑–∞—Ç–µ–º –∏–º–µ–Ω–∞ –∏–∑ –º–æ–¥–µ–ª–∏, –∑–∞—Ç–µ–º generic fallback.
                # –í–∞–∂–Ω–æ: pipe_obstacle ‚â† beam ‚Äî —Ñ–∏–∑–∏—á–µ—Å–∫–∏–π –¥–≤–∏–∂–æ–∫ –¥–æ–ª–∂–µ–Ω –∏—Ö —Ä–∞–∑–ª–∏—á–∞—Ç—å!
                obj_type = (
                    self.BAUFLEX_CLASS_MAP.get(cls)
                    or names.get(cls, f"class_{cls}")
                )

                objects.append({
                    "type": obj_type,
                    "confidence": round(conf, 3),
                    "real_width_m": round(real_w, 3),
                    "real_height_m": round(real_h, 3),
                    "bbox": [x1, y1, x2, y2],
                    "center": [x1 + px_w // 2, y1 + px_h // 2],
                })
        
        return objects


class SceneDiagnostician:
    """
    –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
    
    –£–ª—É—á—à–µ–Ω–∏—è v2.1:
    - –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–π frame (–±–µ–∑ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è)
    - –î–µ—Ç–µ–∫—Ü–∏—è occlusion (–æ–±—Ä–µ–∑–∫–∏ –æ–±—ä–µ–∫—Ç–æ–≤)
    - Resize –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è blur-–∞–Ω–∞–ª–∏–∑–∞
    - –ë–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
    """
    
    # –ü–æ—Ä–æ–≥–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    MIN_BRIGHTNESS = 50
    MAX_BRIGHTNESS = 240
    MIN_CONTRAST = 30
    BLUR_THRESHOLD = 100
    MIN_AR_POINTS = 4
    OPTIMAL_DISTANCE_MIN = 2.0
    OPTIMAL_DISTANCE_MAX = 5.0
    EDGE_THRESHOLD_PX = 20  # –ü–æ—Ä–æ–≥ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±—Ä–µ–∑–∫–∏
    BLUR_ANALYSIS_SIZE = 640  # –°–∂–∏–º–∞–µ–º –¥–æ —ç—Ç–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è

    def check_data_quality(
        self,
        frame: np.ndarray,
        detected_objects: Optional[List[Dict[str, Any]]],
        ar_points: Optional[List[Dict[str, float]]],
        distance: float,
    ) -> Dict[str, Any]:
        """
        –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö.
        
        –í–ê–ñ–ù–û: –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–π frame (–Ω–µ image_bytes) –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏!
        
        Args:
            frame: –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ BGR (H, W, 3)
            detected_objects: —Ä–µ–∑—É–ª—å—Ç–∞—Ç Eyes.analyze_scene()
            ar_points: —Å–ø–∏—Å–æ–∫ AR-—Ç–æ—á–µ–∫ [{x, y, z}, ...]
            distance: —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –æ–±—ä–µ–∫—Ç–∞ (–º)
        
        Returns:
            {
                "is_ready": bool,
                "quality_score": float (0-100),
                "warnings": List[str],
                "instructions": List[str],
                "metrics": {...}
            }
        """
        h, w = frame.shape[:2]
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        gray = self._to_gray(frame)
        
        # –î–ª—è blur-–∞–Ω–∞–ª–∏–∑–∞ —Å–∂–∏–º–∞–µ–º (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)
        gray_small = self._resize_for_blur_analysis(gray)
        
        warnings: List[str] = []
        instructions: List[str] = []
        score = 100.0
        
        # === 1. –Ø–†–ö–û–°–¢–¨ ===
        brightness = float(np.mean(gray))
        
        if brightness < self.MIN_BRIGHTNESS:
            score -= 15
            instructions.append("üí° –°–ª–∏—à–∫–æ–º —Ç–µ–º–Ω–æ! –í–∫–ª—é—á–∏—Ç–µ —Ñ–æ–Ω–∞—Ä–∏–∫ –∏–ª–∏ —É–ª—É—á—à–∏—Ç–µ –æ—Å–≤–µ—â–µ–Ω–∏–µ.")
        elif brightness > self.MAX_BRIGHTNESS:
            score -= 10
            instructions.append("‚òÄÔ∏è –ü–µ—Ä–µ—ç–∫—Å–ø–æ–∑–∏—Ü–∏—è! –£–º–µ–Ω—å—à–∏—Ç–µ —è—Ä–∫–æ—Å—Ç—å –∏–ª–∏ –∏–∑–º–µ–Ω–∏—Ç–µ —É–≥–æ–ª.")
        elif brightness < 80:
            score -= 5
            warnings.append("–û—Å–≤–µ—â–µ–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ, –Ω–æ –ø—Ä–∏–µ–º–ª–µ–º–æ–µ.")
        
        # === 2. –ö–û–ù–¢–†–ê–°–¢ ===
        contrast = float(np.std(gray))
        
        if contrast < self.MIN_CONTRAST:
            score -= 10
            instructions.append("üì∑ –ù–∏–∑–∫–∏–π –∫–æ–Ω—Ç—Ä–∞—Å—Ç. –°–º–µ–Ω–∏—Ç–µ —Ä–∞–∫—É—Ä—Å –∏–ª–∏ –æ—Å–≤–µ—â–µ–Ω–∏–µ.")
        
        # === 3. –†–ê–ó–ú–´–¢–û–°–¢–¨ ===
        blur = self._laplacian_variance(gray_small)
        
        if blur < self.BLUR_THRESHOLD:
            score -= 20
            instructions.append("üîç –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–∞–∑–º—ã—Ç–æ! –°—Ç–∞–±–∏–ª–∏–∑–∏—Ä—É–π—Ç–µ –∫–∞–º–µ—Ä—É –∏–ª–∏ –¥–æ–∂–¥–∏—Ç–µ—Å—å –∞–≤—Ç–æ—Ñ–æ–∫—É—Å–∞.")
        
        # === 4. –†–ê–°–°–¢–û–Ø–ù–ò–ï ===
        if distance < 1.0:
            score -= 15
            instructions.append("üìè –°–ª–∏—à–∫–æ–º –±–ª–∏–∑–∫–æ! –û—Ç–æ–π–¥–∏—Ç–µ –º–∏–Ω–∏–º—É–º –Ω–∞ 2 –º–µ—Ç—Ä–∞.")
        elif distance > 10.0:
            score -= 10
            instructions.append("üìè –°–ª–∏—à–∫–æ–º –¥–∞–ª–µ–∫–æ! –ü–æ–¥–æ–π–¥–∏—Ç–µ –±–ª–∏–∂–µ (–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ 2-5 –º–µ—Ç—Ä–æ–≤).")
        elif distance < self.OPTIMAL_DISTANCE_MIN or distance > self.OPTIMAL_DISTANCE_MAX:
            score -= 5
            warnings.append(f"üìè –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ {distance:.1f}–º. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 2-5–º.")
        
        # === 5. AR-–¢–û–ß–ö–ò ===
        points = ar_points or []
        
        if len(points) < self.MIN_AR_POINTS:
            score -= 15
            instructions.append(
                f"üìç –ú–∞–ª–æ –æ–ø–æ—Ä–Ω—ã—Ö —Ç–æ—á–µ–∫ ({len(points)}/{self.MIN_AR_POINTS}). "
                f"–û—Ç–º–µ—Ç—å—Ç–µ —É–≥–ª—ã –±–∞–ª–æ–∫ –∏–ª–∏ –ø—Ä–µ–ø—è—Ç—Å—Ç–≤–∏–π."
            )
        
        # === 6. –û–ë–ù–ê–†–£–ñ–ï–ù–ù–´–ï –û–ë–™–ï–ö–¢–´ ===
        if not detected_objects:
            score -= 20
            instructions.append("üëÅÔ∏è –û–±—ä–µ–∫—Ç—ã –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω—ã. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ —Å—ä–µ–º–∫—É –ø–æ–¥ –¥—Ä—É–≥–∏–º —É–≥–ª–æ–º.")
        else:
            # === 7. OCCLUSION (–û–ë–†–ï–ó–ö–ê –û–ë–™–ï–ö–¢–û–í) ===
            occlusion_check = self._check_occlusion(detected_objects, w, h)

            if occlusion_check["has_occlusion"]:
                score -= 10
                instructions.append(occlusion_check["message"])

            # === 8. DEPTH OCCLUSION (–ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –æ–¥–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –¥—Ä—É–≥–∏–º) ===
            depth_occlusion = self._check_depth_occlusion(detected_objects)

            if depth_occlusion["has_depth_occlusion"]:
                score -= 10
                warnings.append(depth_occlusion["message"])

            # === 9. AR DRIFT CHECK (—Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã YOLO —Å –¥–∏—Å—Ç–∞–Ω—Ü–∏—è–º–∏ AR-—Ç–æ—á–µ–∫) ===
            ar_drift = self._check_ar_drift(detected_objects, points)

            if ar_drift["has_drift"]:
                score -= 10
                warnings.append(ar_drift["message"])
        
        # === –ò–¢–û–ì–û–í–ê–Ø –û–¶–ï–ù–ö–ê ===
        score = max(0.0, min(100.0, round(score, 1)))

        return {
            "is_ready": score >= 70 and not instructions,
            "quality_score": score,
            "warnings": warnings,
            "instructions": instructions,
            "metrics": {
                "brightness": round(brightness, 2),
                "contrast": round(contrast, 2),
                "blur_laplacian_var": round(blur, 2),
                "distance_m": round(distance, 2),
                "ar_points_count": len(points),
                "detected_objects_count": len(detected_objects or []),
                "depth_occlusion_pairs": (
                    depth_occlusion.get("occluded_pairs", [])
                    if detected_objects else []
                ),
                "ar_drift_detected": (
                    ar_drift.get("has_drift", False)
                    if detected_objects else False
                ),
            },
        }
    
    def _check_occlusion(
        self,
        detected_objects: List[Dict[str, Any]],
        frame_width: int,
        frame_height: int
    ) -> Dict[str, Any]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–µ –æ–±—Ä–µ–∑–∞–Ω—ã –ª–∏ –æ–±—ä–µ–∫—Ç—ã –∫—Ä–∞–µ–º –∫–∞–¥—Ä–∞,
        –∏ –Ω–µ –∑–∞–Ω–∏–º–∞—é—Ç –ª–∏ –æ–Ω–∏ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à—É—é —á–∞—Å—Ç—å –∫–∞–¥—Ä–∞ (–Ω–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞).

        Args:
            detected_objects: —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ —Å bbox
            frame_width, frame_height: —Ä–∞–∑–º–µ—Ä—ã –∫–∞–¥—Ä–∞

        Returns:
            {"has_occlusion": bool, "message": str, "occluded_objects": [...]}
        """
        occluded = []
        frame_area = max(1, frame_width * frame_height)

        for obj in detected_objects:
            bbox = obj.get("bbox", [])
            if len(bbox) != 4:
                continue

            x1, y1, x2, y2 = bbox

            # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ 1: –æ–±—Ä–µ–∑–∫–∞ –∫—Ä–∞–µ–º –∫–∞–¥—Ä–∞ ---
            near_left   = x1 < self.EDGE_THRESHOLD_PX
            near_right  = x2 > frame_width  - self.EDGE_THRESHOLD_PX
            near_top    = y1 < self.EDGE_THRESHOLD_PX
            near_bottom = y2 > frame_height - self.EDGE_THRESHOLD_PX

            if near_left or near_right or near_top or near_bottom:
                direction = []
                if near_left:   direction.append("—Å–ª–µ–≤–∞")
                if near_right:  direction.append("—Å–ø—Ä–∞–≤–∞")
                if near_top:    direction.append("—Å–≤–µ—Ä—Ö—É")
                if near_bottom: direction.append("—Å–Ω–∏–∑—É")

                occluded.append({
                    "type": obj.get("type", "unknown"),
                    "direction": ", ".join(direction),
                    "reason": "edge_crop",
                })
                continue  # –ù–µ—Ç —Å–º—ã—Å–ª–∞ –ø—Ä–æ–≤–µ—Ä—è—Ç—å ¬´—Å–ª–∏—à–∫–æ–º –±–ª–∏–∑–∫–æ¬ª –¥–ª—è —É–∂–µ –æ–±—Ä–µ–∑–∞–Ω–Ω–æ–≥–æ

            # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ 2: –æ–±—ä–µ–∫—Ç –∑–∞–Ω–∏–º–∞–µ—Ç >80% –∫–∞–¥—Ä–∞ (–Ω–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞) ---
            obj_area = (x2 - x1) * (y2 - y1)
            coverage = obj_area / frame_area

            if coverage > 0.80:
                occluded.append({
                    "type": obj.get("type", "unknown"),
                    "direction": "–≤–µ—Å—å –∫–∞–¥—Ä",
                    "reason": "too_close",
                    "coverage_pct": round(coverage * 100, 1),
                })

        if occluded:
            edge_crop = [o for o in occluded if o.get("reason") == "edge_crop"]
            too_close = [o for o in occluded if o.get("reason") == "too_close"]

            messages = []
            if edge_crop:
                types = ", ".join(set(o["type"] for o in edge_crop))
                messages.append(
                    f"üìê –û–±—ä–µ–∫—Ç '{types}' –æ–±—Ä–µ–∑–∞–Ω –∫—Ä–∞–µ–º –∫–∞–¥—Ä–∞. "
                    f"–û—Ç–æ–π–¥–∏—Ç–µ –Ω–∞ 3 –º–µ—Ç—Ä–∞ –∏ –≤–æ–∑—å–º–∏—Ç–µ —Ä–∞–∫—É—Ä—Å —à–∏—Ä–µ."
                )
            if too_close:
                types = ", ".join(set(o["type"] for o in too_close))
                messages.append(
                    f"üì∑ –û–±—ä–µ–∫—Ç '{types}' –∑–∞–Ω–∏–º–∞–µ—Ç >80% –∫–∞–¥—Ä–∞ ‚Äî –Ω–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è "
                    f"—Ç–æ—á–µ–∫ –∫—Ä–µ–ø–ª–µ–Ω–∏—è. –û—Ç–æ–π–¥–∏—Ç–µ –¥–∞–ª—å—à–µ, —á—Ç–æ–±—ã –∑–∞—Ö–≤–∞—Ç–∏—Ç—å –æ–∫—Ä—É–∂–µ–Ω–∏–µ."
                )

            return {
                "has_occlusion": True,
                "message": " | ".join(messages),
                "occluded_objects": occluded,
            }

        return {"has_occlusion": False, "message": "", "occluded_objects": []}
    
    def _check_ar_drift(
        self,
        detected_objects: List[Dict[str, Any]],
        ar_points: List[Dict[str, float]],
    ) -> Dict[str, Any]:
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä—ã –æ–±—ä–µ–∫—Ç–æ–≤ –∏–∑ YOLO —Å —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è–º–∏ –º–µ–∂–¥—É AR-—Ç–æ—á–∫–∞–º–∏.

        –ï—Å–ª–∏ YOLO –≥–æ–≤–æ—Ä–∏—Ç ¬´–±–∞–ª–∫–∞ 2 –º¬ª, –∞ AR-—Ç–æ—á–∫–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç ¬´3 –º¬ª ‚Äî
        –ø—Ä–æ–∏–∑–æ—à—ë–ª AR-–¥—Ä–∏—Ñ—Ç –∏–ª–∏ YOLO –æ—à–∏–±—Å—è. –í –æ–±–æ–∏—Ö —Å–ª—É—á–∞—è—Ö –Ω—É–∂–Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–¥–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

        –ê–ª–≥–æ—Ä–∏—Ç–º:
          1. –ë–µ—Ä—ë–º —Å–∞–º—ã–π —à–∏—Ä–æ–∫–∏–π beam –∏–∑ YOLO (—Ä–µ–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –≤ –º–µ—Ç—Ä–∞—Ö).
          2. –í—ã—á–∏—Å–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É AR-—Ç–æ—á–∫–∞–º–∏ –ø–æ –æ—Å—è–º X –∏ Z.
          3. –ï—Å–ª–∏ —Ä–∞–∑—Ä—ã–≤ > DRIFT_TOLERANCE ‚Äî —Å–∏–≥–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏.

        Args:
            detected_objects: —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ (–¥–æ–ª–∂–Ω—ã —Å–æ–¥–µ—Ä–∂–∞—Ç—å real_width_m)
            ar_points: —Å–ø–∏—Å–æ–∫ AR-—Ç–æ—á–µ–∫ [{x, y, z}, ...]

        Returns:
            {"has_drift": bool, "message": str, "details": dict}
        """
        DRIFT_TOLERANCE = 0.40  # 40 —Å–º ‚Äî –¥–æ–ø—É—Å—Ç–∏–º–æ–µ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ

        if len(ar_points) < 2 or not detected_objects:
            return {"has_drift": False, "message": "", "details": {}}

        # –®–∏—Ä–∏–Ω–∞ —Å–∞–º–æ–≥–æ –∫—Ä—É–ø–Ω–æ–≥–æ beam'–∞ –ø–æ YOLO
        beam_widths = [
            obj["real_width_m"]
            for obj in detected_objects
            if obj.get("type") == "beam" and "real_width_m" in obj
        ]

        if not beam_widths:
            # –ï—Å–ª–∏ –Ω–µ—Ç beam'–æ–≤ ‚Äî –±–µ—Ä—ë–º –ª—é–±–æ–π –∫—Ä—É–ø–Ω—ã–π –æ–±—ä–µ–∫—Ç
            beam_widths = [
                obj["real_width_m"]
                for obj in detected_objects
                if "real_width_m" in obj
            ]

        if not beam_widths:
            return {"has_drift": False, "message": "", "details": {}}

        yolo_size = max(beam_widths)

        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É AR-—Ç–æ—á–∫–∞–º–∏ –≤ –ø–ª–æ—Å–∫–æ—Å—Ç–∏ XZ (–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å)
        xs = [p.get("x", 0.0) for p in ar_points]
        zs = [p.get("z", 0.0) for p in ar_points]
        ar_span_x = max(xs) - min(xs)
        ar_span_z = max(zs) - min(zs)
        ar_span = max(ar_span_x, ar_span_z)

        delta = abs(yolo_size - ar_span)

        if delta > DRIFT_TOLERANCE:
            return {
                "has_drift": True,
                "message": (
                    f"üì° AR-–¥—Ä–∏—Ñ—Ç –∏–ª–∏ –æ—à–∏–±–∫–∞ –ò–ò: YOLO –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —à–∏—Ä–∏–Ω—É –æ–±—ä–µ–∫—Ç–∞ {yolo_size:.2f} –º, "
                    f"–∞ AR-—Ç–æ—á–∫–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç {ar_span:.2f} –º (—Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ {delta:.2f} –º). "
                    f"–ü–µ—Ä–µ—Å–∫–∞–Ω–∏—Ä—É–π—Ç–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –∏–ª–∏ –ø–µ—Ä–µ—Å—Ç–∞–≤—å—Ç–µ AR-–º–∞—Ä–∫–µ—Ä—ã."
                ),
                "details": {
                    "yolo_size_m": round(yolo_size, 3),
                    "ar_span_m": round(ar_span, 3),
                    "delta_m": round(delta, 3),
                },
            }

        return {"has_drift": False, "message": "", "details": {}}

    def _check_depth_occlusion(
        self,
        detected_objects: List[Dict[str, Any]],
    ) -> Dict[str, Any]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –æ–¥–Ω–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –¥—Ä—É–≥–∏–º–∏ (Depth Occlusion).

        –ï—Å–ª–∏ –±–∞–ª–∫–∞ —á–∞—Å—Ç–∏—á–Ω–æ –∑–∞–∫—Ä—ã—Ç–∞ –¥—Ä—É–≥–∏–º –æ–±—ä–µ–∫—Ç–æ–º, –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ª–µ—Å–æ–≤ –Ω–µ —Å–º–æ–∂–µ—Ç
        –Ω–∞–π—Ç–∏ —Ç–æ—á–∫–∏ –∫—Ä–µ–ø–ª–µ–Ω–∏—è –Ω–∞ –ø–µ—Ä–µ–∫—Ä—ã—Ç–æ–π —á–∞—Å—Ç–∏.

        –ê–ª–≥–æ—Ä–∏—Ç–º: –¥–ª—è –∫–∞–∂–¥–æ–π –ø–∞—Ä—ã –æ–±—ä–µ–∫—Ç–æ–≤ –≤—ã—á–∏—Å–ª—è–µ–º IoU (Intersection over Union).
        –ï—Å–ª–∏ IoU > –ø–æ—Ä–æ–≥–∞ ‚Äî –æ–¥–∏–Ω –æ–±—ä–µ–∫—Ç –ø–µ—Ä–µ–∫—Ä—ã–≤–∞–µ—Ç –¥—Ä—É–≥–æ–π.

        Args:
            detected_objects: —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ —Å bbox

        Returns:
            {"has_depth_occlusion": bool, "message": str, "occluded_pairs": [...]}
        """
        OVERLAP_THRESHOLD = 0.15  # 15% –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è —Å—á–∏—Ç–∞–µ—Ç—Å—è –∑–Ω–∞—á–∏–º—ã–º –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º

        occluded_pairs = []

        for i, obj_a in enumerate(detected_objects):
            for j, obj_b in enumerate(detected_objects):
                if j <= i:
                    continue  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –ø–∞—Ä—É –æ–¥–∏–Ω —Ä–∞–∑

                bbox_a = obj_a.get("bbox", [])
                bbox_b = obj_b.get("bbox", [])

                if len(bbox_a) != 4 or len(bbox_b) != 4:
                    continue

                ax1, ay1, ax2, ay2 = bbox_a
                bx1, by1, bx2, by2 = bbox_b

                # –ü–ª–æ—â–∞–¥—å –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
                inter_x1 = max(ax1, bx1)
                inter_y1 = max(ay1, by1)
                inter_x2 = min(ax2, bx2)
                inter_y2 = min(ay2, by2)

                if inter_x2 <= inter_x1 or inter_y2 <= inter_y1:
                    continue  # –ù–µ—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è

                inter_area = (inter_x2 - inter_x1) * (inter_y2 - inter_y1)
                area_a = max(1, (ax2 - ax1) * (ay2 - ay1))
                area_b = max(1, (bx2 - bx1) * (by2 - by1))
                union_area = area_a + area_b - inter_area

                iou = inter_area / union_area
                overlap_of_smaller = inter_area / min(area_a, area_b)

                if overlap_of_smaller > OVERLAP_THRESHOLD:
                    occluded_pairs.append({
                        "object_a": obj_a.get("type", "unknown"),
                        "object_b": obj_b.get("type", "unknown"),
                        "overlap_pct": round(overlap_of_smaller * 100, 1),
                    })

        if occluded_pairs:
            pair_desc = "; ".join(
                f"'{p['object_a']}' ‚Üî '{p['object_b']}' ({p['overlap_pct']}%)"
                for p in occluded_pairs
            )
            return {
                "has_depth_occlusion": True,
                "message": (
                    f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤: {pair_desc}. "
                    f"–ò–ò –º–æ–∂–µ—Ç –Ω–µ –Ω–∞–π—Ç–∏ —Ç–æ—á–∫–∏ –∫—Ä–µ–ø–ª–µ–Ω–∏—è –Ω–∞ –ø–µ—Ä–µ–∫—Ä—ã—Ç—ã—Ö —É—á–∞—Å—Ç–∫–∞—Ö. "
                    f"–°—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä—É–π—Ç–µ —ç–ª–µ–º–µ–Ω—Ç—ã –æ—Ç–¥–µ–ª—å–Ω–æ."
                ),
                "occluded_pairs": occluded_pairs,
            }

        return {"has_depth_occlusion": False, "message": "", "occluded_pairs": []}

    def _to_gray(self, frame: np.ndarray) -> np.ndarray:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç BGR –≤ grayscale."""
        if CV2_AVAILABLE:
            return cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # Fallback —á–µ—Ä–µ–∑ numpy (BGR ‚Üí Gray)
        # –í–µ—Å–∞ –¥–ª—è BGR: B=0.114, G=0.587, R=0.299
        return np.dot(frame[..., :3], [0.114, 0.587, 0.299]).astype(np.uint8)
    
    def _resize_for_blur_analysis(self, gray: np.ndarray) -> np.ndarray:
        """
        –°–∂–∏–º–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–æ BLUR_ANALYSIS_SIZE –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è.
        Laplacian –Ω–∞ –±–æ–ª—å—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö –º–µ–¥–ª–µ–Ω–Ω—ã–π!
        
        Args:
            gray: grayscale –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        
        Returns:
            –£–º–µ–Ω—å—à–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        """
        h, w = gray.shape[:2]
        
        # –ï—Å–ª–∏ —É–∂–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–∞–ª–µ–Ω—å–∫–æ–µ, –Ω–µ —Ç—Ä–æ–≥–∞–µ–º
        if max(h, w) <= self.BLUR_ANALYSIS_SIZE:
            return gray
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–∞—Å—à—Ç–∞–±
        scale = self.BLUR_ANALYSIS_SIZE / max(h, w)
        new_w = int(w * scale)
        new_h = int(h * scale)
        
        if CV2_AVAILABLE:
            return cv2.resize(gray, (new_w, new_h), interpolation=cv2.INTER_AREA)
        else:
            # Fallback —á–µ—Ä–µ–∑ numpy (–ø—Ä–æ—Å—Ç–æ–µ —Å–∂–∞—Ç–∏–µ)
            step_h = max(1, h // new_h)
            step_w = max(1, w // new_w)
            return gray[::step_h, ::step_w]
    
    def _laplacian_variance(self, gray: np.ndarray) -> float:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç –≤–∞—Ä–∏–∞—Ü–∏—é Laplacian (–º–µ—Ä–∞ —Ä–µ–∑–∫–æ—Å—Ç–∏).
        –ß–µ–º –±–æ–ª—å—à–µ –∑–Ω–∞—á–µ–Ω–∏–µ, —Ç–µ–º —Ä–µ–∑—á–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.
        
        Args:
            gray: grayscale –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        
        Returns:
            –í–∞—Ä–∏–∞—Ü–∏—è Laplacian (float)
        """
        if CV2_AVAILABLE:
            laplacian = cv2.Laplacian(gray, cv2.CV_64F)
            return float(laplacian.var())
        
        # Fallback —á–µ—Ä–µ–∑ numpy gradient
        gy, gx = np.gradient(gray.astype(float))
        return float(np.var(gx) + np.var(gy))


class VisionSystem:
    """
    –§–∞—Å–∞–¥, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∏–π –¥–µ—Ç–µ–∫—Ç–æ—Ä –∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É.
    
    –£–ª—É—á—à–µ–Ω–∏—è v2.1:
    - –ï–¥–∏–Ω–æ–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    - –ü–µ—Ä–µ–¥–∞—á–∞ –≥–æ—Ç–æ–≤–æ–≥–æ frame –≤ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É
    """

    def __init__(self, model_path: str = "yolov8n.pt") -> None:
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è.
        
        Args:
            model_path: –ø—É—Ç—å –∫ YOLO –º–æ–¥–µ–ª–∏
        """
        self.eyes = Eyes(model_path=model_path)
        self.diagnostician = SceneDiagnostician()
        logger.info("‚úì VisionSystem initialized")

    def process_scene(
        self,
        image_bytes: bytes,
        distance: float,
        ar_points: Optional[List[Dict[str, float]]] = None,
        focal_length: Optional[float] = None,
        focal_length_x: Optional[float] = None,
        focal_length_y: Optional[float] = None,
    ) -> Dict[str, Any]:
        """
        –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ü–µ–Ω—ã.
        
        –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –î–µ–∫–æ–¥–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ–¥–∏–Ω —Ä–∞–∑!
        
        Args:
            image_bytes: –±–∞–π—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            distance: —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –æ–±—ä–µ–∫—Ç–∞ (–º)
            ar_points: –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, AR-—Ç–æ—á–∫–∏
            focal_length: —Ñ–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (—É—Å—Ç–∞—Ä–µ–≤—à–∏–π)
            focal_length_x, focal_length_y: —Ñ–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø–æ –æ—Å—è–º
        
        Returns:
            {
                "objects": [...],
                "quality": {...},
                "ready_for_design": bool
            }
        """
        try:
            # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –î–µ–∫–æ–¥–∏—Ä—É–µ–º –û–î–ò–ù —Ä–∞–∑, –ø–µ—Ä–µ–¥–∞–µ–º –≥–æ—Ç–æ–≤—ã–π frame –≤ –æ–±–∞ –º–æ–¥—É–ª—è
            frame = self.eyes._decode_image_bgr(image_bytes)

            # 1. –î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ ‚Äî –ø–µ—Ä–µ–¥–∞–µ–º –≥–æ—Ç–æ–≤—ã–π frame, –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–Ω—É—Ç—Ä–∏ –ù–ï –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è
            detected_objects = self.eyes.analyze_scene(
                frame=frame,
                distance_to_target=distance,
                focal_length=focal_length,
                focal_length_x=focal_length_x,
                focal_length_y=focal_length_y,
            )
            
            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (–ø–µ—Ä–µ–¥–∞–µ–º –≥–æ—Ç–æ–≤—ã–π frame!)
            quality = self.diagnostician.check_data_quality(
                frame,  # –ì–æ—Ç–æ–≤—ã–π frame, –Ω–µ image_bytes!
                detected_objects,
                ar_points or [],
                distance
            )
            
            return {
                "objects": detected_objects,
                "quality": quality,
                "ready_for_design": quality["is_ready"]
            }
        
        except Exception as e:
            logger.error(f"Error in process_scene: {e}")
            return {
                "objects": [],
                "quality": {
                    "is_ready": False,
                    "quality_score": 0,
                    "instructions": [f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}"],
                    "warnings": [],
                    "metrics": {}
                },
                "ready_for_design": False
            }


# === –£–¢–ò–õ–ò–¢–´ –î–õ–Ø –û–ë–†–ê–¢–ù–û–ô –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò ===

def check_dependencies() -> Dict[str, bool]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π.
    
    Returns:
        {"cv2": bool, "PIL": bool, "YOLO": bool}
    """
    return {
        "cv2": CV2_AVAILABLE,
        "PIL": PIL_AVAILABLE,
        "YOLO": YOLO_AVAILABLE
    }


def get_recommended_focal_length(camera_info: Optional[Dict[str, Any]] = None) -> Tuple[float, float]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ —Ñ–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ.
    
    Args:
        camera_info: –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–∞–Ω–Ω—ã–µ –∏–∑ ARCore CameraIntrinsics
    
    Returns:
        (fx, fy) tuple
    """
    if camera_info:
        fx = camera_info.get("focal_length_x")
        fy = camera_info.get("focal_length_y")
        
        if fx and fy:
            return (fx, fy)
    
    # Default –¥–ª—è —Ç–∏–ø–∏—á–Ω—ã—Ö —Å–º–∞—Ä—Ç—Ñ–æ–Ω–æ–≤
    return (800.0, 800.0)


# === –≠–ö–°–ü–û–†–¢ ===
__all__ = [
    "Eyes",
    "SceneDiagnostician",
    "VisionSystem",
    "check_dependencies",
    "get_recommended_focal_length",
]
